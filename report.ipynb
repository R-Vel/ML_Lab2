{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f0c1f1-0c6d-42bc-b992-38a61ca855e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:54:37.766927Z",
     "iopub.status.busy": "2025-10-28T16:54:37.765536Z",
     "iopub.status.idle": "2025-10-28T16:54:38.044246Z",
     "shell.execute_reply": "2025-10-28T16:54:38.042890Z",
     "shell.execute_reply.started": "2025-10-28T16:54:37.766863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from model import WhiteBox\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bea90",
   "metadata": {},
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">Executive Summary</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6c48c",
   "metadata": {},
   "source": [
    "St. James Hospital’s “Baby Monitor” ML model produced misclassifications of newborn risk, leading to patient fatality. The model’s unreliability and lack of transparency have jeopardized patient safety and eroded the trust of the hospital staff. The Organization for Whitebox ModeLs (OWL) was commissioned to diagnose these failures. Our objective is to propose a new, robust methodology for model development—validated by a proof-of-concept model—and a governance framework that ensures clear explanations and effective human oversight.\n",
    "\n",
    "Our evaluation of the original model identified critical flaws. The system was optimized for overall accuracy rather than patient safety, a critical error for an imbalanced dataset. This focus resulted in a dangerously low 57.1% recall rate for at-risk infants, meaning it failed to identify nearly half of the babies in danger. Furthermore, our analysis of the misclassifications revealed the model systematically failed to flag risk in infants from an underrepresented demographic, indicating a significant data bias. The proposed methodology improves the performance of the model through several steps. First, data points were split by baby to avoid data leakage. Second, the sampling technique SMOTENC was used to balance the distribution between the healthy and at-risk babies. Third, random forest was tuned and modeled using unscaled numerical features and one-hot encoded categorical features. Finally, probabilities were outputed to capture the model's confidence with the prediciton. Our proposed proof-of-concept (a transparent decision tree) shows that these changes significally improved the model, achieving a 95% recall rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304d4b5-5d3e-49bc-b671-f8aaff9c47be",
   "metadata": {},
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">I. Introduction</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77122ad-b3e3-462b-9d18-801cfbac2e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:24:29.888070Z",
     "iopub.status.busy": "2025-10-17T07:24:29.887321Z",
     "iopub.status.idle": "2025-10-17T07:24:29.894929Z",
     "shell.execute_reply": "2025-10-17T07:24:29.893251Z",
     "shell.execute_reply.started": "2025-10-17T07:24:29.888006Z"
    }
   },
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Overview</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bbbdc2-4715-4dd0-b359-4c98bf1baa2c",
   "metadata": {},
   "source": [
    "The Organization for Whitebox ModeLs (OWL) was commissioned by St. James Hospital to audit the Baby Monitor Project, an AI-based system developed by Data Monitors for the hospital’s OB-GYN department. The system was designed to predict newborn risk levels and support staff in providing timely care.\n",
    "\n",
    "Although the project initially showed strong results in improving efficiency and patient satisfaction, a series of misclassifications, one of which resulted in a fatality, prompted serious concerns regarding the model’s accuracy and transparency.\n",
    "\n",
    "This report summarizes OWL’s independent assessment of the Baby Monitor model and outlines findings, issues, and recommendations to guide St. James Hospital in strengthening the safety, reliability, and governance of future AI solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354908d-a89a-41c5-bd21-139c717e61d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:24:29.888070Z",
     "iopub.status.busy": "2025-10-17T07:24:29.887321Z",
     "iopub.status.idle": "2025-10-17T07:24:29.894929Z",
     "shell.execute_reply": "2025-10-17T07:24:29.893251Z",
     "shell.execute_reply.started": "2025-10-17T07:24:29.888006Z"
    }
   },
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Problem</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b059496-4fc0-49be-8a5b-520b1b892963",
   "metadata": {},
   "source": [
    "The main issue being faced  is the severe failures of the ‘Baby Monitor’ ML model, which has led to patient fatalities due to misclassifications. These errors can be derived from several different  key factors.\n",
    "\n",
    "First is Model Opacity. How did the erroneous model make its predictions, and what faulty logic did it use? The lack of transparency makes it unclear how the model reaches its conclusions.\n",
    "\n",
    "Next, a  deeper M=misclassification analysis is needed to identify what features or patterns caused the twelve \"false negative\" cases, along with what those errors reveal about the model's decision-making process.\n",
    "\n",
    "There are also potential methodological flaws in the original approach. This includes the preprocessing, model selection, and evaluation metrics; these have likely reduced the ability for the model to detect \"at risk\" infants with sufficient accuracy.\n",
    "\n",
    "Finally, governance and oversight gaps seem to play a major role in the issues faced. The lack of a proper or robust human review processes and risk management frameworks led to system errors going unnoticed until the consequences become too severe.\n",
    "\n",
    "In short, the challenges highlight the technical weaknesses and limited accountability structure being the primary reasons that patients get affected by these errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901438c-8f05-40d9-9b9b-ffbb687e0dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:24:29.888070Z",
     "iopub.status.busy": "2025-10-17T07:24:29.887321Z",
     "iopub.status.idle": "2025-10-17T07:24:29.894929Z",
     "shell.execute_reply": "2025-10-17T07:24:29.893251Z",
     "shell.execute_reply.started": "2025-10-17T07:24:29.888006Z"
    }
   },
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Project Objectives</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7436a6-c7c0-4d2d-a6ab-c82ec0db1d65",
   "metadata": {},
   "source": [
    "This assessment aims to tackle two main objectives. The first objective is to investigate and interpret the erroneous model. Interpreting the model allows OWL and St. James Hospital to discover the logic behind its predictions, cross-reference the findings with healthcare practitioners, and troubleshoot faulty steps in preprocessing the data and training the model. This entails understanding the behavior of the model, particularly in detecting the most prominent patterns in predicting the health of the 12 misclassified babies, to see where the model went wrong.\n",
    "\n",
    "The second objective is to propose a better methodology and framework that reduces the risks of misclassifications and ensures that any errors are quickly detected and mitigated. The new machine learning model developed will serve as a proof-of-concept that this method works and can transparently provide clear explanations for its decisions. The framework also entails seamlessly integrating the model into the workflow and educating stakeholders on proper intervention. This framework will serve as a template for future machine learning modeling efforts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcba018-aa28-496d-b5f0-070db9d2cf63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:24:29.888070Z",
     "iopub.status.busy": "2025-10-17T07:24:29.887321Z",
     "iopub.status.idle": "2025-10-17T07:24:29.894929Z",
     "shell.execute_reply": "2025-10-17T07:24:29.893251Z",
     "shell.execute_reply.started": "2025-10-17T07:24:29.888006Z"
    }
   },
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Significance of the Report</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71eed2-5ece-422b-9540-7c9131d4ad75",
   "metadata": {},
   "source": [
    "This report is significant because it's our direct response to the 'Baby Monitor' model's severe failures and shortcomings. Aside from being a technical review, it's a crucial step toward rebuilding trust between hospitals and patients towards these kinds of models while also guaranteeing patient safety.\n",
    "\n",
    "By breaking down why the Data Monitors model failed, this report provides St. James Hospital with a clear diagnosis of methodological flaws. More importantly, it establishes a benchmark for the 'correct' way to develop, validate, and govern clinical AI systems.\n",
    "\n",
    "Ultimately, the significance is twofold: it provides an immediate, safer, and more transparent alternative for newborn risk assessment, and it delivers a robust, understandable framework that can guide all future AI adoption within the hospital, ensuring that technology serves as a reliable and trustworthy aid to medical practitioners rather than a liability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b316636-7980-4e92-aedd-1501c957a773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:26:47.273808Z",
     "iopub.status.busy": "2025-10-17T07:26:47.273082Z",
     "iopub.status.idle": "2025-10-17T07:26:47.280513Z",
     "shell.execute_reply": "2025-10-17T07:26:47.278847Z",
     "shell.execute_reply.started": "2025-10-17T07:26:47.273748Z"
    }
   },
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">II. Methodology</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5061c15-0858-414d-8206-d90deb865ad6",
   "metadata": {},
   "source": [
    "The methodology is as follows:\n",
    "\n",
    "1. Data Collection \n",
    "    Data was provided of St. James Hospital’s historical records for 70 babies. Exploratory Data Analysis will be used to understand the dataset: duplicate values, distributions for each feature, and other patterns present with the data. \n",
    "\n",
    "2. Evaluation of Data Monitor’s Model\n",
    "    The original model, its specification, and its accuracies (recall, precision, accuracy), were also provided by St. James Hospital. The models were run to identify the model’s current classification report. Preprocessing steps were analyzed and implied based on the model specifications and parameters. Then, the pre-processing, modelling, and evaluation metrics were critiqued. \n",
    "\n",
    "3. Analysis of the Misclassified Babies\n",
    "    SHAP was used to analyze the decisions behind classifying the 12 babies as healthy. By applying SHAP on both an individual instance and a group instance, stakeholders can recognize which features have a large influence on the final prediction and lead to the misclassification.\n",
    "\n",
    "4. Improved Model\n",
    "\tGiven the previous observations, the team suggests more appropriate preprocessing methods, model types, and evaluation metrics for detecting and classifying newborn risk levels. The new model will also be interpreted through SHAP to showcase the contribution of each feature to this new model’s predictions, and particularly in discrepancies that possibly misclassified the 12 false negatives. \n",
    "\n",
    "5. Robust Framework \n",
    "    Finally, the team suggests ways to seamlessly integrate the system into the hospital’s workflow. The framework allows for human intervention so that errors are easily mitigated. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0904e38",
   "metadata": {},
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">III. Data Description</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5be4c",
   "metadata": {},
   "source": [
    "The `historical.csv` dataset contains 2,100 observations and 25 features representing longitudinal monitoring data of newborns. It integrates demographic and clinical variables to facilitate early identification of potential health risks in infants.\n",
    "\n",
    "\n",
    "The dataset includes both baseline characteristics recorded at birth and daily follow-up measurements, allowing for analysis of growth trajectories and vital sign stability over time. Continuous variables such as `weight`, `temperature`, and `oxygen saturation` reflect clinical conditions, while categorical variables capture developmental indicators.\n",
    "\n",
    "| **Feature Name**              | **Feature Description**                            | **Data Type** |\n",
    "| :----------------------------: | :------------------------------------------------: | :------------: |\n",
    "| `baby_id`                     | Unique identifier for each baby                    | string        |\n",
    "| `name`                        | Name of the baby                                   | string        |\n",
    "| `gender`                      | Gender of the baby (Male/Female)                   | string        |\n",
    "| `gestational_age_weeks`       | Gestational age at birth (normal: 37–42 weeks)     | float         |\n",
    "| `birth_weight_kg`             | Weight of the baby at birth (normal: 2.5–4.5 kg)   | float         |\n",
    "| `birth_length_cm`             | Length of the baby at birth (average: 48–52 cm)    | float         |\n",
    "| `birth_head_circumference_cm` | Head circumference at birth (average: 33–35 cm)    | float         |\n",
    "| `date`                        | Monitoring date                                    | string (date) |\n",
    "| `age_days`                    | Age of the baby in days since birth                | integer       |\n",
    "| `weight_kg`                   | Recorded daily weight                              | float         |\n",
    "| `length_cm`                   | Recorded daily body length                         | float         |\n",
    "| `head_circumference_cm`       | Recorded daily head circumference                  | float         |\n",
    "| `temperature_c`               | Body temperature in °C (normal: 36.5–37.5)         | float         |\n",
    "| `heart_rate_bpm`              | Heart rate (normal: 120–160 bpm)                   | integer       |\n",
    "| `respiratory_rate_bpm`        | Respiratory rate (normal: 30–60 bpm)               | integer       |\n",
    "| `oxygen_saturation`           | Oxygen saturation level (normal >95%)              | integer       |\n",
    "| `feeding_type`                | Type of feeding: Breastfeeding, Formula, or Mixed  | string        |\n",
    "| `feeding_frequency_per_day`   | Number of feeds per day (normal: 8–12)             | integer       |\n",
    "| `urine_output_count`          | Wet diaper count per day (normal: 6–8+)            | integer       |\n",
    "| `stool_count`                 | Bowel movements per day (0–5 typical)              | integer       |\n",
    "| `jaundice_level_mg_dl`        | Bilirubin level (normal <5, mild 5–12, severe >15) | float         |\n",
    "| `apgar_score`                 | APGAR score at birth (0–10, recorded on day 1)     | float         |\n",
    "| `immunizations_done`          | Immunizations completed (Yes/No)                   | string        |\n",
    "| `reflexes_normal`             | Whether newborn reflexes are normal (Yes/No)       | string        |\n",
    "| `risk_level`                  | Target variable: Healthy (0) or At Risk (1)        | string        |\n",
    "\n",
    "</div>\n",
    "\n",
    "The `risk_level` variable serves as the target feature, representing the infant’s overall health classification. Analytical models developed using this dataset aim to predict or classify newborns as Healthy or At Risk based on observed developmental and physiological indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a2a56-ac5d-4b3b-a62a-ddc0a6e83fdc",
   "metadata": {},
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Evaluation Metrics</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfea042-6621-4522-ae77-512ec6900a8d",
   "metadata": {},
   "source": [
    "To get a better idea of how the team evaluates the models, the following section will define the different evaluation metrics to be discussed in this report:\n",
    "\n",
    "- Recall - Known also as the sensitivity or true positive rate. It measures the proportion of all actual at-risk babies that were correctly identified by the model and is the crucial metric for patient safety, as high recall minimizes false negatives (babies who are at risk but are classified as healthy).\n",
    "- Precision - Known also as the positive predictive value. It measures the proportion of babies the model predicted to be at risk that were actually at risk. High precision minimizes false positives which is often prioritized for hospital efficiency.\n",
    "- Accuracy - Is the proportion of the total number of correct predictions which is calculated as the ratio of correct predictions (true positives or negatives) to the total number of predictions. Used often as an overall metric of performance, it can be misleading in imbalanced datasets, like this one where \"at-risk\" babies are the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120796d-5311-4bbf-9f10-9dde7ec0240e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:28:47.786970Z",
     "iopub.status.busy": "2025-10-17T07:28:47.785657Z",
     "iopub.status.idle": "2025-10-17T07:28:47.792985Z",
     "shell.execute_reply": "2025-10-17T07:28:47.791431Z",
     "shell.execute_reply.started": "2025-10-17T07:28:47.786906Z"
    }
   },
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">IV. Evaluation of Data Monitor’s Model</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9425d-fa27-4b53-ad9d-489aa837a9b9",
   "metadata": {},
   "source": [
    "Data Monitor provided St. James’ Hospital with a model that acts as a Baby Monitor for the OBGYN Ward. The model provides a daily prediction of whether the baby is healthy or at risk based on various factors. It preprocessed the data based on its data type and ensured that each feature was understood by the machine. Then, it used Logistic Regression to learn and identify patterns within the dataset. Finally, the model developing team used precision as their evaluation metric to assess the performance of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94745dfa-0e2c-45b8-bf7a-802b175000b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:57:42.162135Z",
     "iopub.status.busy": "2025-10-28T16:57:42.161454Z",
     "iopub.status.idle": "2025-10-28T16:58:24.143984Z",
     "shell.execute_reply": "2025-10-28T16:58:24.142712Z",
     "shell.execute_reply.started": "2025-10-28T16:57:42.162076Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data frame\n",
    "df = pd.read_csv('historical.csv')\n",
    "fn_details = pd.read_csv('corrected_false_negatives.csv')\n",
    "\n",
    "# get complete columns for false negative babies\n",
    "fn_df = fn_details.merge(df, \n",
    "                         on=fn_details.columns.tolist(), \n",
    "                         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0b22d5-977f-4586-bb39-2c14e04e04d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:58:24.145652Z",
     "iopub.status.busy": "2025-10-28T16:58:24.145391Z",
     "iopub.status.idle": "2025-10-28T16:58:24.179644Z",
     "shell.execute_reply": "2025-10-28T16:58:24.178660Z",
     "shell.execute_reply.started": "2025-10-28T16:58:24.145627Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsdsba2027/rvelasco/.local/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/bsdsba2027/rvelasco/.local/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/bsdsba2027/rvelasco/.local/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/bsdsba2027/rvelasco/.local/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/bsdsba2027/rvelasco/.local/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load old model for audit\n",
    "model = joblib.load('old_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "026d5683-a7b2-4972-8a7d-5005a58774e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:58:24.180516Z",
     "iopub.status.busy": "2025-10-28T16:58:24.180292Z",
     "iopub.status.idle": "2025-10-28T16:58:24.215784Z",
     "shell.execute_reply": "2025-10-28T16:58:24.214882Z",
     "shell.execute_reply.started": "2025-10-28T16:58:24.180496Z"
    }
   },
   "outputs": [],
   "source": [
    "# get features used in old model\n",
    "\n",
    "features = {}\n",
    "for row in model.named_steps['preprocess'].transformers_:\n",
    "    dtype, preprocess, col_list = row\n",
    "    features[dtype] = col_list\n",
    "\n",
    "all_features = [col for cols in features.values() for col in cols]\n",
    "\n",
    "target_col = \"risk_level\"\n",
    "X = df.drop(columns=[target_col])\n",
    "X = df[all_features]\n",
    "fn_df = fn_df[all_features]\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f60dea8-3155-4c1a-aa03-bf5431a55675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:58:24.217646Z",
     "iopub.status.busy": "2025-10-28T16:58:24.217108Z",
     "iopub.status.idle": "2025-10-28T16:58:24.657983Z",
     "shell.execute_reply": "2025-10-28T16:58:24.656244Z",
     "shell.execute_reply.started": "2025-10-28T16:58:24.217624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9808/907404551.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = df['risk_level'].replace({'Healthy': 0, 'At Risk': 1}).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.926\n",
      "F1: 0.684\n",
      "Precision: 0.780\n",
      "Recall: 0.608\n",
      "===============================\n",
      "Test Accuracy: 0.919\n",
      "F1: 0.684\n",
      "Precision: 0.762\n",
      "Recall: 0.571\n",
      "===============================\n",
      "Test Set Confusion Matrix:\n",
      "      0   1\n",
      "0  354  10\n",
      "1   24  32\n"
     ]
    }
   ],
   "source": [
    "y = df['risk_level'].replace({'Healthy': 0, 'At Risk': 1}).values\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Predict train set\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"F1: {train_f1:.3f}\")\n",
    "print(f\"Precision: {train_precision:.3f}\")\n",
    "print(f\"Recall: {train_recall:.3f}\")\n",
    "\n",
    "# Predict test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# 8. Print results\n",
    "print(\"===============================\")\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(f\"F1: {f1:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(\"===============================\")\n",
    "print(\"Test Set Confusion Matrix:\\n\", pd.DataFrame(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a994d-3840-4b24-8e60-8152c76554f3",
   "metadata": {},
   "source": [
    "One flaw of the audited model is the overreliance of accuracy as the only metric. Accuracy is used to determine whether the model’s predictions align with the babies’ actual risk. Our audit revealed that the original model had a high test accuracy of 91.9% . However, analysis into the distribution of the data reveals that the distribution between classes are imbalanced. Healthy instances make up 1822 records in the database while only 278 instances were classified as at risk. Imbalanced datasets have difficulty capturing patterns of the smaller class. Therefore, the high accuracy of the model is misleading because it can achieve a high accuracy by merely predicting the majority, i.e. “Healthy,” without properly detecting the minority class. \n",
    "\n",
    "A better metric to use for this case is recall.  Recall, or the true positive rate, measure how many at-risk babies were properly flagged by the model among all the at-risk babies. A low recall, like the 57.1% from the original model, indicates that the model is not able to properly detect nearly half of the babies that actually need medical attention. While relying on recall might lead to false negatives, i.e. healthy babies prematurely flagged as at-risk, it is better to remain cautious and conduct additional screenings earlier instead of detecting risk too late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70feb55b-3ae5-4504-b5cc-804fda3d045e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T17:00:08.815458Z",
     "iopub.status.busy": "2025-10-28T17:00:08.814745Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['float64','int64'])\n",
    "\n",
    "numeric_df[['heart_rate_bpm','jaundice_level_mg_dl']].hist(\n",
    "    figsize=(6,5),\n",
    "    bins= 20,\n",
    "    edgecolor='black',\n",
    "    grid=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09bc9fb-32eb-4c7d-9d5e-a036506eac32",
   "metadata": {},
   "source": [
    "In addition, the distributions of the features in the dataset violate the assumptions of a linear model. Some, like heart rate and weight, follow a relatively normal distribution. Others, like urine output and stool count, are uniformly distributed, with a relatively equal number of data points per category. Finally, a few, like jaundice, are bimodal distributions. Since linear models assume multivariate normality, it finds it difficult to process features without heavily preprocessing the data to be normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f1df3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/d3aDLA7.png\" alt=\"Boxplots of Numerical Features\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b30a6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 1. Feature Importance of the Initial Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcad2d9",
   "metadata": {},
   "source": [
    "Figure 1 shows the feature importance of the model provided by Data Monitor. It is evident that jaundice level is the most influential predictor, with heart rate and oxygen saturation following as key indicators, reflecting how the model weighs signs of distress versus stability.\n",
    "Further directionality and feature interactions will be detailed in the upcoming SHAP analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bcdea4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/SnFkXa5.png\" alt=\"Boxplots of Numerical Features\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28062815",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 2. Global SHAP Summary Plot of the Initial Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed1cb29",
   "metadata": {},
   "source": [
    "The global SHAP summary plot gives a view of how each feature influences the model’s predictions, with both magnitude and direction of influence, showing how risk predictions change depending on the baby’s physiological profile. As seen above, jaundice level remains the strongest determinant of neonatal risk. Given the heavy distribution of blue points, this indicates that higher bilirubin values consistently push predictions toward the “At Risk” side. This confirms the model’s strong sensitivity to jaundice. Beyond jaundice, heart rate, oxygen saturation, and weight also shape the decision boundary of the model. Increased heart rate, lower oxygen saturation, and lower weight values tend to increase predicted risk.\n",
    "\n",
    "To further interpret the model’s decision logic, we can later inspect the decision boundary and distribution for jaundice level specifically. This would help visualize how the model separates “Healthy” vs. “At Risk” infants and reveal the approximate threshold at which jaundice becomes critical in classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1410200",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/rvMtKpC.png\" alt=\"Boxplots of Numerical Features\" width=\"750\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221cd30",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 3. Partial Dependence Plot of Risk on Jaundice Level\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82196f63",
   "metadata": {},
   "source": [
    "Figure 3 displays the Partial Dependence Plot (PDP) of baby health on jaundice level. The plot shows that the model’s predicted probability of a baby being classified as 'At Risk' changes as bilirubin levels increase. The curve shows a strong and nonlinear relationship, where risk remains minimal below approximately 5 mg/dL, then rises sharply beyond 8–10 mg/dL, where the model predicts a significantly higher likelihood of classifying baby health as being at risk.\n",
    "\n",
    "The insights from the PDP complements the above global SHAP analysis that ranked jaundice as the top predictor influencing model decisions. However, the PDP shows that the model’s reliance is not only strong, but also has a threshold or decision boundary, meaning that predictions change rapidly around a certain value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd9bd1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/qhBWGC6.png\" alt=\"Boxplots of Numerical Features\" width=\"750\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09d241",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 4. Scatter Plot of Jaundice Levels by Baby Health Status\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a711b1",
   "metadata": {},
   "source": [
    "Figure 4 shows a scatter plot on the distribution of jaundice levels among infants, differentiated by their health status. Blue dots indicate healthy infants and red dots represent those classified as at risk.\n",
    "\n",
    "There is clear decision boundary present in the health classification of babies based on their level of jaundice. Most healthy babies cluster within lower jaundice levels of 0–5 mg/dL, with the decision boundary being around 10 mg/dL; Cases beyond that level are commonly classified as being at risk. This plot trend suggests that higher bilirubin concentrations are strongly associated with elevated health risks.\n",
    "\n",
    "However, the scatter plot also reveals a potential class imbalance, where healthy cases appear to heavily outnumber at-risk cases, as seen in the heavy clustering of healthy cases between 2-4 mg/dL. This imbalance may contribute to misclassifications where the model may struggle to correctly identify subtle cases of elevated risk due to the dominance of healthy examples in the training data.\n",
    "\n",
    "Although this plot reflects raw observed data rather than model predictions, it effectively highlights both the clinical significance of jaundice level and the impact of data distribution on model performance — underscoring the need for balanced datasets or resampling techniques to improve classification reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8136b0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/YOY5deo.png\" alt=\"Boxplots of Numerical Features\" width=\"750\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccdad3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 5. Bar Graph of Class Imbalance on the Decision Boundary (10 mg/dL)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88939b7c",
   "metadata": {},
   "source": [
    "Figure 5 presents a bar chart comparing the number of infants with jaundice levels above and below the 10 mg/dL threshold among selected instances. The majority of babies fall within the <10 mg/dL group, while a smaller subset exceeds 10 mg/dL. This distribution reinforces the class imbalance observed earlier, where most babies exhibit normal or moderately elevated bilirubin levels, while only a limited number display severe jaundice. Such imbalance can influence model performance as the classifier may become biased toward predicting the more common category and underperform when identifying rare high-risk cases.\n",
    "\n",
    "To address this, the proposed model aims to reduce dependency on jaundice alone by incorporating a broader set of physiological and developmental features, such as weight, reflexes, feeding type, and immunization status. By diversifying the feature space and rebalancing the training data, the new model is expected to achieve better generalization and fairer predictions across all baby health profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168485fc-c7c3-4abb-bdf0-37600a46fa87",
   "metadata": {},
   "source": [
    "<a href=\"https://ibb.co/jxJJFn1\"><img src=\"https://i.ibb.co/wbcc15x/Screen-Shot-2025-10-17-at-10-19-50-PM.png\" alt=\"Screen-Shot-2025-10-17-at-10-19-50-PM\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aba126-00f1-4e4e-bb0f-d4ff3002bcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:19:02.822904Z",
     "iopub.status.busy": "2025-10-28T16:19:02.821882Z",
     "iopub.status.idle": "2025-10-28T16:19:02.971616Z",
     "shell.execute_reply": "2025-10-28T16:19:02.969377Z",
     "shell.execute_reply.started": "2025-10-28T16:19:02.822788Z"
    }
   },
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 6. Global SHAP Values of Audited Model\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcbc174-801e-4c49-bf72-313acbfecce5",
   "metadata": {},
   "source": [
    "Figure 6 is a beeswarm plot of the cumulative Shapley values of the false negative babies. The group instance tells us how high and low values of the features impact the model outcome, giving us better and more actionable insights.\n",
    "\n",
    "1. Lower values for jaundice, heart rate, and the baby’s age in days have had a significant contribution to mislabelling the babies as healthy, which is in line with the single instance plot.\n",
    "2. Higher values of weight and oxygen saturation have also significantly pulled the prediction lower\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d378f169-be9f-4dc7-b84b-92a5aa0d739b",
   "metadata": {},
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Local Interpretability (Individual Instance)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aeff02-bd21-4ce1-931c-6f74fc9e5cdd",
   "metadata": {},
   "source": [
    "To explain why the babies were misclassified, this section will use LIME (Local Interpretable Model-agnostic Explanations) to explore individual instances and group instances that could have led to misclassifying these babies as ‘healthy’. LIME provides local explanations by approximating the model’s behavior around a single instance and highlight which specific features influenced that prediction the most.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/Z2raNTL.png\" alt=\"Boxplots of Numerical Features\" width=\"900\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dddf11-5593-4a36-8fba-c2ac729c9949",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<p style=\"text-align: center; font-size: 14px; margin-bottom: 30px; margin-left: 20px; font-style: italic;\">\n",
    "    Figure 7. LIME Explanation of Instance #729\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Figure 7 shows the LIME explanation for Instance #729, a baby with a jaundice level of 4.9 mg/dL, which is distant from the model’s decision boundary of roughly 10 mg/dL. Clinically, this baby should have been labeled as 'At Risk', yet the model predicted it as 100% healthy. This proves the case that the model is completely reliant on jaundice; A strong case of boundary-driven misclassification.\n",
    "\n",
    "The LIME results show that the model placed heavy weight on the low jaundice level, which dominated the prediction and neglected other relevant indicators such as lower gestational age and smaller head circumference. While these latter features would typically correlate with higher risk, their influence was minimal compared to jaundice, which led to a 100% confidence of classifying the instance as 'Healthy.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f283189-5ff3-4997-abe9-bd10d19f5fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:28:47.786970Z",
     "iopub.status.busy": "2025-10-17T07:28:47.785657Z",
     "iopub.status.idle": "2025-10-17T07:28:47.792985Z",
     "shell.execute_reply": "2025-10-17T07:28:47.791431Z",
     "shell.execute_reply.started": "2025-10-17T07:28:47.786906Z"
    }
   },
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">V. Improved Model</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0584ffb-1e39-4f36-9cb1-de22d2c81408",
   "metadata": {},
   "source": [
    "Several modifications were made to improve performance and address key issues found in the audit.\n",
    "\n",
    "First, instead of the default train-test-split, the data points were grouped per baby ID before splitting. One issue arising from the audit are unrealistic test scores for tree-based models. The dataset contains multiple records per baby, with birth features, namely gestational age, birth weight, birth length, birth head circumference, and apgar score not changing among records.  While personally identifiable information like baby ID and name were initially dropped, the model may still be able to implicitly detect the specific baby through its birth details. Grouping the records by baby id before splitting ensures that each baby only appears in one of three sets: train, validation, test set. This prevents data leakage and improves generalizability with unseen babies.\n",
    "\n",
    "\n",
    "\n",
    "Another step implemented before modelling was SMOTENC. SMOTENC is a sampling technique that handles both numerical and categorical variables. It creates synthetic data points of the minority class to balance the distribution between the two classes. These data points are generated by interpolating between the nearest at-risk cases to make them similar approximations to the original data. This technique improves generalizability by helping the model reduce the bias toward only predicting the majority class.\n",
    "\n",
    "Random search was conducted to determine the best method and hyperparameters that resulted in the best recall and F1 score. Instead of Logistic Regression, the proposed method uses RandomForest instead. A random forest model fits the dataset because it is non-parametric. In addition, a random forest model is able to reduce overfitting by averaging the predictions of multiple decision trees. Since Random Forest models are insensitive to scaling, the standard scaler preprocessor was removed from the pipeline with the one-hot encoding retained. \n",
    "\n",
    "Finally, instead of using absolute class predictions, the model outputs the model’s predicted probability that a baby belongs to the “at risk” group. There is no strict cutoff between healthy and unhealthy, so using probabilities shows how confident or uncertain the model is with its classification. This provides a more nuanced view of risk, allowing medical personnel to see and intervene based on their domain expertise. For example, a record with probabilities of 55% healthy and 45% at risk is more uncertain that a record with probabilities of 90% healthy and 10% at risk, so medical personnel can use this information to screen babies near the threshold.\n",
    "\n",
    "The tuned random forest model improved the test recall score to 95% and the f1 score to 92%. While these scores are more encouraging, the confusion matrix still reveals to at-risk babies from the test set misclassified as healthy. Another big challenge of the original model is the lack of explainability. Explainable models allow the user to see the factors that influence the model’s prediction. To enhance transparency and support clinical trust, model explainability was introduced using LIME. LIME, or Local Interpretable Model-Agnostic Explanations provides insight into features most strongly influenced by the model’s decisions for a specific case. This addition allows clinicians and data monitors to better understand why the model flagged (or did not flag) a baby as at risk, determine if these factors are realistic, and intervene accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb7890-589c-414a-a6d8-089f281187f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [(\"clf\", WhiteBox())]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "results.append({\n",
    "        'Model': name,\n",
    "        'Train_Acc': accuracy_score(y_train, y_train_pred),\n",
    "        'Val_Acc': accuracy_score(y_val, y_val_pred),\n",
    "        'Train_F1': f1_score(y_train, y_train_pred),\n",
    "        'Val_F1': f1_score(y_val, y_val_pred),\n",
    "        'Train_Precision': precision_score(y_train, y_train_pred),\n",
    "        'Val_Precision': precision_score(y_val, y_val_pred),\n",
    "        'Train_Recall': recall_score(y_train, y_train_pred),\n",
    "        'Val_Recall': recall_score(y_val, y_val_pred),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='Val_F1', ascending=False).reset_index(drop=True)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007ab5f-3275-4917-977e-0f81208e9102",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:54.751230Z",
     "iopub.status.idle": "2025-10-28T16:54:54.751512Z",
     "shell.execute_reply": "2025-10-28T16:54:54.751390Z",
     "shell.execute_reply.started": "2025-10-28T16:54:54.751377Z"
    }
   },
   "outputs": [],
   "source": [
    "model = pipe.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e85ae-5216-454d-9d1a-357461bc7249",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:54.752172Z",
     "iopub.status.idle": "2025-10-28T16:54:54.752445Z",
     "shell.execute_reply": "2025-10-28T16:54:54.752325Z",
     "shell.execute_reply.started": "2025-10-28T16:54:54.752302Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='Importance', y='Feature', data=model._get_feature_importance())\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd305981-c403-42c2-93d4-8fa9fd6a20ba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:54.753047Z",
     "iopub.status.idle": "2025-10-28T16:54:54.753286Z",
     "shell.execute_reply": "2025-10-28T16:54:54.753180Z",
     "shell.execute_reply.started": "2025-10-28T16:54:54.753169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "instance = fn_df[(fn_df['baby_id'] == 'B025') & (fn_df['date'] == '2025-04-19')]  \n",
    "explanation = model._explain_instance(instance)\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc63220-49e9-4dc2-a4a9-58e8867fc77a",
   "metadata": {},
   "source": [
    "Finally, to support the decision-making process of the doctors in St. James' Hospital, a Local Interpretable Model-agnostic Explanation (LIME) will be provided. LIME could provide doctors with a concrete probability of the patients’ health status. For instance, for the same baby misclassified by the data monitor's model, baby 25, because the improved model has reduced its dependency on juandice, the probability that he was healthy decreased. However, it was not enough to correctly classify him as ‘at risk’. Therefore, highlighting the importance of doctor intervention. After identifying what features have affected the predictions, the doctor could decide to implement an alternative course of action based on their own experiences and unquantifiable observations on the patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac8c6f-2aed-4162-b595-f277e05fcc79",
   "metadata": {},
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">VI. Proposed Framework</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67804ea4-f259-48ff-93a2-9637a8bec324",
   "metadata": {},
   "source": [
    "The Organization of Whitebox Models (OWL) is a non-profit organization that provides accreditation for the following:\n",
    "\n",
    "Data Management Association – Certified Data Management Professional (DAMA-CDMP), \n",
    "International Institute of Business Analysis – Certification in Business Data Analytics (IIBA-CBDA), \n",
    "International Organization for Standardization (ISO), and \n",
    "General Data Protection Regulation (GDPR)\n",
    "\n",
    "Therefore, to conduct the audit process for Data Monitor's model, these organizations' standardization process would be used to first identify and locate the source of the issue, and second, to create an improved framework that embodies OWL's mission of advocating ethical use of Machine Learning models through transparency. Therefore, upon further investigation, St. James' Hospital and Data Monitors have failed to uphold three key standards: 1) Privacy and Security, 2) Model Interpretability and Explainability, and 3) Human Intervention.\n",
    "\n",
    "The data set provided by St. James' hospital fails to meet the Privacy and Security practices of the DAMA-CDMP and GDPR. Providing real names that can be used as an identifier for the babies can unnecessarily breach the confidentiality codes of the health industry. DAMA-CDMP and GDPR encourage firms to collect only necessary data. Therefore, identifiers such as names that do not contribute to the prediction or performance of the model should not be included in future data collection. However, it is understood that it would be beneficial for hospitals to keep and maintain a record of patients that can be used for future doctor visits or appointments. Therefore, to address this need, the public data set could retain the column baby_id that allows hospitals and patients to look back at the babies' history by using these as identifiers for their sealed records.\n",
    "Secondly, IIBA-CBDA, ISO Standards, and GDPR all discourage the overreliance on artificial intelligence (AI). IIBA-CBDA advocates that data analytics should only support decision-making processes, but not replace them. On the other hand, GDPR and ISO Standards express the need for human involvement. In fact, Article 22 prohibits fully automated decisions that significantly affect individuals. Despite these regulations, St. James Hospital has failed to comply and has become overdependent on these models to classify the health of these babies. This can be visualized in Figure 1, where, after the model makes a prediction, the doctors in the hospital fail to verify the prediction in exchange for efficiency. Therefore, in the second figure, to improve the framework, human intervention was added to ensure the doctor's expert opinion will be a necessary step before choosing a course of action.\n",
    "\n",
    "Finally, to aid the doctor in implementing the best course of action for the baby, a missing segment in the model's framework is an explainability model. IIBA-CBDA advocates quality results interpretation and communication to industry professionals, while ISO/IEC 23894 aims to ensure that there is transparency and risk controls for ML models. Therefore, to mitigate the risk, such as death or missing a critical diagnosis, that comes with healthy babies being misclassified, an explainability model could be used to help doctors identify what is causing at-risk babies to be labelled as healthy. Therefore, adding this step still maintains efficiency by allowing doctors to bypass the extensive monitoring process, but it also provides a better explanation for the model at a glance. Therefore, doctors can base their professional opinions on a more concrete and interpretable visualization as compared to being overreliant on the data predictions themselves.\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/tYXAR5C.png\" alt=\"Initial Framework\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://imgur.com/8hnb2n0.png\" alt=\"Proposed Framework\" width=\"670\">\n",
    "</div>\n",
    "\n",
    "Additionally, to ensure that the model remains reliable and useful for the hospital staff, it is also suggested that an assigned employee of St. James' hospital will take responsibility in consistently evaluating the model's performance metric. For instance, a significant drop in the model performance could indicate a bug, human error, or there may be a need to use a better classifier model. Therefore, these instances must be reported directly to the team to prevent misclassifications and to find a solution as soon as possible, so as not to compromise the efficiency rate of the hospital. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862a79f-1b24-4c15-be43-8ceba39d0091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:28:47.786970Z",
     "iopub.status.busy": "2025-10-17T07:28:47.785657Z",
     "iopub.status.idle": "2025-10-17T07:28:47.792985Z",
     "shell.execute_reply": "2025-10-17T07:28:47.791431Z",
     "shell.execute_reply.started": "2025-10-17T07:28:47.786906Z"
    }
   },
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">VII. Conclusions and Recommendations</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7082c9-9797-426b-b187-55585aa87120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5ac4a9a-5cc6-4540-8eaf-57704c9e071f",
   "metadata": {},
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Limitations</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81db3dc-8152-4f7c-af40-15bb4c0cc44a",
   "metadata": {},
   "source": [
    "Despite the modified model significantly improving the performance Data Monitor's intial system, the study still comes with certain limitations:\n",
    "\n",
    "1. Limited Feature Scope- The model relies on a lot of quantitative features and less of contextual data. Therefore, doctor's notes and maternal health information could help nurses and doctors better determine the health of the baby.\n",
    "\n",
    "2. Limited Interpretability in Complex Models- Although tree-based models provide better evealuation metrics, they also increase the risk of overfitting and reduced transparency. Even with SHAP interpreting hundreds of possible feature interaction could be difficult for hospital personell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ad79f-e1ce-4c4d-a79b-10fce2479b6c",
   "metadata": {},
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Recommendations</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61b1b7-d3aa-45db-a397-6f75b7c74b41",
   "metadata": {},
   "source": [
    "To further the study, here are some recommendations to improve the model:\n",
    "\n",
    "1. Expand and Diversify the Dataset- To improve the quality of the dataset, future researchers can collect related datasets from other hospitalsor different demographic regions. Doing so, can improve generability across certain areas or countries.\n",
    "\n",
    "2. Implement Class Balancing Techniques- To improve effectivity of adressing class imbalance, it would be encouraged to combine and explore other sampling methods, like ADASYN. If done properly, it could increase the performance of the non tree-based models to reduce chances of overfitting and increase transparency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0e838-455e-4ec6-92ef-a9b45a8d1a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T07:28:47.786970Z",
     "iopub.status.busy": "2025-10-17T07:28:47.785657Z",
     "iopub.status.idle": "2025-10-17T07:28:47.792985Z",
     "shell.execute_reply": "2025-10-17T07:28:47.791431Z",
     "shell.execute_reply.started": "2025-10-17T07:28:47.786906Z"
    }
   },
   "source": [
    "# <div style=\"background-color:#00357A; padding:20px; border-radius:10px; color:white; width:auto;\">Supplementary Materials</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973a278-4bba-443e-9b4a-e1a762faaf45",
   "metadata": {},
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Loading Files</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632074b5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.121288Z",
     "iopub.status.idle": "2025-10-28T16:54:22.121530Z",
     "shell.execute_reply": "2025-10-28T16:54:22.121423Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.121412Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Partial Dependence Plot for Jaundice Level ---\n",
    "fig, ax = plt.subplots(figsize=(8, 5))  # smaller aspect ratio\n",
    "\n",
    "disp = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_train,\n",
    "    features=['jaundice_level_mg_dl'],\n",
    "    ax=ax,\n",
    "    kind='average',\n",
    "    grid_resolution=100\n",
    ")\n",
    "\n",
    "# --- Adjust scaling and formatting ---\n",
    "ax.set_xlim(0, 15)                    # jaundice range\n",
    "ax.set_ylim(0, 0.8)                   # matches your plotted range\n",
    "ax.set_xlabel('Jaundice Level (mg/dL)', fontsize=12)\n",
    "ax.set_ylabel('Partial Dependence (Predicted Risk)', fontsize=12)\n",
    "ax.set_title('Partial Dependence of Risk on Jaundice Level', fontsize=14)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218d06a-2f92-4f38-bb87-bfdfaf0759fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T13:53:19.659345Z",
     "iopub.status.busy": "2025-10-17T13:53:19.656473Z",
     "iopub.status.idle": "2025-10-17T13:53:19.666731Z",
     "shell.execute_reply": "2025-10-17T13:53:19.665450Z",
     "shell.execute_reply.started": "2025-10-17T13:53:19.659243Z"
    }
   },
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Exploratory Data Analysis</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a347dee-0f4f-4dc9-a0d3-1b0646b74d56",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.122178Z",
     "iopub.status.idle": "2025-10-28T16:54:22.122445Z",
     "shell.execute_reply": "2025-10-28T16:54:22.122306Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.122292Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"apgar_score\"] = df[\"apgar_score\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2bc92-3dd2-488c-a8cc-cee39f02395c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.123032Z",
     "iopub.status.idle": "2025-10-28T16:54:22.123276Z",
     "shell.execute_reply": "2025-10-28T16:54:22.123163Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.123153Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce66e9b-6b0e-483a-9a43-81803dc738eb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.124289Z",
     "iopub.status.idle": "2025-10-28T16:54:22.124564Z",
     "shell.execute_reply": "2025-10-28T16:54:22.124445Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.124430Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['baby_id', 'name', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016cc2d-c0be-4561-b6ab-ed26528a7115",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.125126Z",
     "iopub.status.idle": "2025-10-28T16:54:22.125371Z",
     "shell.execute_reply": "2025-10-28T16:54:22.125252Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.125242Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_numeric_df = df.select_dtypes(exclude=['number'])\n",
    "\n",
    "for col in non_numeric_df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    non_numeric_df[col].value_counts(dropna=False).plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e85113b-6173-4a9d-8412-c913a2aebcbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:26:06.605592Z",
     "iopub.status.busy": "2025-10-28T16:26:06.604851Z",
     "iopub.status.idle": "2025-10-28T16:26:06.613303Z",
     "shell.execute_reply": "2025-10-28T16:26:06.611598Z",
     "shell.execute_reply.started": "2025-10-28T16:26:06.605529Z"
    }
   },
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Hyperparameter Tuning</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae92cd-1e46-491f-a6b3-fe57622256f0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.126714Z",
     "iopub.status.idle": "2025-10-28T16:54:22.126945Z",
     "shell.execute_reply": "2025-10-28T16:54:22.126841Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.126831Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- STEP 1: Define Feature Types -----------\n",
    "# Sepeparate features by data types\n",
    "numerical_features_std = ['weight_kg', 'length_cm',\n",
    "                     'head_circumference_cm', 'temperature_c', 'heart_rate_bpm', 'respiratory_rate_bpm',\n",
    "                     'oxygen_saturation', 'jaundice_level_mg_dl']\n",
    "\n",
    "numerical_features_minmax = ['age_days', 'feeding_frequency_per_day','urine_output_count',\n",
    "                             'stool_count']\n",
    "\n",
    "numerical_features = numerical_features_std + numerical_features_minmax\n",
    "categorical_features = ['feeding_type', 'gender','immunizations_done', 'reflexes_normal']\n",
    "   \n",
    "drop_col = ['baby_id', 'name', 'date', 'gestational_age_weeks', 'birth_weight_kg', \n",
    "                     'birth_length_cm', 'birth_head_circumference_cm','apgar_score']\n",
    "df['risk_level'] = df['risk_level'].replace({'Healthy': 0, 'At Risk': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141fd55d-e55d-4583-a826-4f1e8756bdc3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.127361Z",
     "iopub.status.idle": "2025-10-28T16:54:22.127589Z",
     "shell.execute_reply": "2025-10-28T16:54:22.127485Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.127475Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- STEP 2: Train-Test Split by Baby -----------\n",
    "# Get unique babies\n",
    "unique_babies = df['baby_id'].unique()\n",
    "\n",
    "# Split babies, not records\n",
    "Train_babies, test_babies = train_test_split(\n",
    "    unique_babies, test_size=0.15, random_state=0\n",
    ")\n",
    "\n",
    "# Split babies, not records\n",
    "train_babies, val_babies = train_test_split(\n",
    "    Train_babies, test_size=0.15, random_state=0\n",
    ")\n",
    "\n",
    "# Filter dataframe\n",
    "train_df = df[df['baby_id'].isin(train_babies)].copy()\n",
    "val_df = df[df['baby_id'].isin(val_babies)].copy()\n",
    "test_df = df[df['baby_id'].isin(test_babies)].copy()\n",
    "\n",
    "# Now fill within each set\n",
    "train_df['apgar_score'] = train_df.groupby('baby_id')['apgar_score'].ffill()\n",
    "val_df['apgar_score'] = val_df.groupby('baby_id')['apgar_score'].ffill()\n",
    "test_df['apgar_score'] = test_df.groupby('baby_id')['apgar_score'].ffill()\n",
    "\n",
    "X_train = train_df.drop(columns='risk_level')\n",
    "X_train = X_train.drop(columns=drop_col)\n",
    "y_train = train_df['risk_level']\n",
    "\n",
    "X_val = val_df.drop(columns='risk_level')\n",
    "X_val = X_val.drop(columns=drop_col)\n",
    "y_val = val_df['risk_level']\n",
    "\n",
    "X_test = test_df.drop(columns='risk_level')\n",
    "X_test = X_test.drop(columns=drop_col)\n",
    "y_test = test_df['risk_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ff3fc-b478-469e-8dbb-1eb21f3f3d2a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.128200Z",
     "iopub.status.idle": "2025-10-28T16:54:22.128437Z",
     "shell.execute_reply": "2025-10-28T16:54:22.128331Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.128321Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- STEP 3: Preprocessing Pipeline -----------\n",
    "\n",
    "lr_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_std', StandardScaler(), numerical_features_std),\n",
    "        ('num_minmax', MinMaxScaler(), numerical_features_minmax),\n",
    "        ('cat', OneHotEncoder(drop=\"if_binary\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_std', 'passthrough', numerical_features_std),\n",
    "        ('num_minmax', 'passthrough', numerical_features_minmax),\n",
    "        ('cat', OneHotEncoder(drop=\"if_binary\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessors = {\n",
    "    'Logistic Regression (L2)': lr_preprocessor,\n",
    "    'Logistic Regression (L1)': lr_preprocessor,\n",
    "    'Random Forest': rf_preprocessor\n",
    "}\n",
    "\n",
    "# Parameter grids for hyperparameter tuning\n",
    "params = {\n",
    "    'Logistic Regression (L2)': {\n",
    "        'smote__k_neighbors': [3, 5, 7],\n",
    "        'clf__C': [1e-3, 1e-2, 1e-1, 1],\n",
    "    },\n",
    "    'Logistic Regression (L1)': {\n",
    "        'smote__k_neighbors': [3, 5, 7],\n",
    "        'clf__C': [1e-3, 1e-2, 1e-1, 1],\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'smote__k_neighbors': [3, 5, 7],\n",
    "        'clf__n_estimators': [100, 200, 300],\n",
    "        'clf__max_depth': [1, 2, 3],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression (L2)': LogisticRegression(penalty = 'l2', max_iter=1000, solver='liblinear', random_state=42),\n",
    "    'Logistic Regression (L1)': LogisticRegression(penalty = 'l1', max_iter=1000, solver='liblinear', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bab6c-249e-4c2f-bdce-13888f97663f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.129154Z",
     "iopub.status.idle": "2025-10-28T16:54:22.129409Z",
     "shell.execute_reply": "2025-10-28T16:54:22.129286Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.129276Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- STEP 4: Hyperparameter Tune with Val Set -----------\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Fit preprocessor to get categorical feature indices\n",
    "    preprocessor = preprocessors[name].fit(X_train)\n",
    "    feature_names_out = preprocessor.get_feature_names_out()\n",
    "    \n",
    "    numerical_count = len(numerical_features)\n",
    "    new_categorical_features = preprocessor.named_transformers_['cat']\n",
    "    categorical_count = len(new_categorical_features.get_feature_names_out())\n",
    "    indices = list(range(numerical_count, numerical_count + categorical_count))\n",
    "\n",
    "    # Declare pipeline\n",
    "    pipe = imb_pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"smote\", SMOTENC(categorical_features=indices,\n",
    "                          random_state=42)),\n",
    "        (\"clf\", model)\n",
    "        \n",
    "    ])\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    rcv = RandomizedSearchCV(pipe, params[name], \n",
    "                             random_state=0, scoring='recall', cv=kfold)\n",
    "    search = rcv.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = search.best_params_\n",
    "    best_model = search.best_estimator_\n",
    "    print(best_params)\n",
    "    trained_models[name] = best_model\n",
    "\n",
    "    # Get prediction probabilities\n",
    "    threshold = 0.5\n",
    "    y_train_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "    y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    y_train_pred = (y_train_proba >= threshold).astype(int)\n",
    "    y_val_pred = (y_val_proba >= threshold).astype(int)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train_Acc': accuracy_score(y_train, y_train_pred),\n",
    "        'Val_Acc': accuracy_score(y_val, y_val_pred),\n",
    "        'Train_F1': f1_score(y_train, y_train_pred),\n",
    "        'Val_F1': f1_score(y_val, y_val_pred),\n",
    "        'Train_Precision': precision_score(y_train, y_train_pred),\n",
    "        'Val_Precision': precision_score(y_val, y_val_pred),\n",
    "        'Train_Recall': recall_score(y_train, y_train_pred),\n",
    "        'Val_Recall': recall_score(y_val, y_val_pred),\n",
    "    })\n",
    "\n",
    "# ----------- STEP 5: Show Results -----------\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='Val_Recall', ascending=False).reset_index(drop=True)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c130b3-fbf7-46a8-b919-88d692ba6f2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.130182Z",
     "iopub.status.idle": "2025-10-28T16:54:22.130422Z",
     "shell.execute_reply": "2025-10-28T16:54:22.130303Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.130293Z"
    }
   },
   "outputs": [],
   "source": [
    "best_pipe = trained_models[results_df.loc[0,'Model']]\n",
    "best_model = best_pipe.named_steps['clf']\n",
    "\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "FEATURE_NAMES_NEW = preprocessor.get_feature_names_out()\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': FEATURE_NAMES_NEW,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf473c-b21b-421c-a710-ee8cada8334f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.131012Z",
     "iopub.status.idle": "2025-10-28T16:54:22.131367Z",
     "shell.execute_reply": "2025-10-28T16:54:22.131137Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.131126Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See result of best model on test set\n",
    "y_train_proba = best_pipe.predict_proba(X_train)[:, 1]\n",
    "y_train_pred = (y_train_proba >= threshold).astype(int)\n",
    "\n",
    "y_test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= threshold).astype(int)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ca0f0-45ce-4487-a08f-78f68ea10dc9",
   "metadata": {},
   "source": [
    "## <div style=\"background-color:#0081CC; padding:10px; border-radius:10px; color:white; width:auto;\">Hyperparameter Tuning</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730cd24",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.131957Z",
     "iopub.status.idle": "2025-10-28T16:54:22.132183Z",
     "shell.execute_reply": "2025-10-28T16:54:22.132078Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.132068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read test.csv file\n",
    "prediction = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Drop identifiable and birth details\n",
    "X_prediction = prediction.drop(columns=drop_col)\n",
    "id_prediction = prediction['baby_id']\n",
    "\n",
    "# Predict outcomes using best model\n",
    "y_prediction = pipe.predict_proba(X_prediction)[:,1]\n",
    "df_prediction = pd.DataFrame({\"id\": id_prediction, \n",
    "                              \"At Risk Outcome\": y_prediction})\n",
    "\n",
    "df_prediction.to_csv(\"model_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e2436-6911-458a-8362-d9612c5e8c4e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-28T16:54:22.132809Z",
     "iopub.status.idle": "2025-10-28T16:54:22.133037Z",
     "shell.execute_reply": "2025-10-28T16:54:22.132932Z",
     "shell.execute_reply.started": "2025-10-28T16:54:22.132922Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(pipe, \"new_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c825084-238d-42ea-a71c-4a45b291a82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
